{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Generating Dataset ====== #\n",
    "r = np.random.rand(10000) * 3\n",
    "theta = np.random.rand(10000) * 2*np.pi\n",
    "\n",
    "y = r.astype(int)\n",
    "r = r * (np.cos(theta) + 1)\n",
    "\n",
    "x1 = r * np.cos(theta)\n",
    "x2 = r * np.sin(theta)\n",
    "X = np.array([x1, x2]).T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ====== Split Dataset into Train, Validation, Test ====== #\n",
    "train_X, train_y = X[:8000, :], y[:8000]\n",
    "val_X, val_y = X[8000:9000, :], y[8000:9000]\n",
    "test_X, test_y = X[9000:, :], y[9000:]\n",
    "\n",
    "# ====== Visualize Each Dataset ====== #\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.scatter(train_X[:,0], train_X[:,1], c=train_y, s=0.7)\n",
    "ax1.set_xlabel('x1'); ax1.set_ylabel('x2')\n",
    "ax1.set_title('Train Dataset Distribution')\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.scatter(val_X[:,0], val_X[:,1], c=val_y, s=0.7)\n",
    "ax2.set_xlabel('x1'); ax2.set_ylabel('x2')\n",
    "ax2.set_title('Validation Dataset Distribution')\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.scatter(test_X[:,0], test_X[:,1], c=test_y, s=0.7)\n",
    "ax3.set_xlabel('x1'); ax3.set_ylabel('x2')\n",
    "ax3.set_title('Test Dataset Distribution')\n",
    "\n",
    "plt.show()"
   ],
   "id": "cee402e1d31cf1cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ====== Hypothesis Define ====== #\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(in_features=2, out_features=3, bias=True)\n",
    "        # self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=2, out_features=200)\n",
    "        self.linear2 = nn.Linear(in_features=200, out_features=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# model = LinearModel()\n",
    "# print(model.linear.weight)\n",
    "# print(model.linear.bias)"
   ],
   "id": "56393c0cf24bf3ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## **Cost Functions in Deep Learning Classification**\n",
    "\n",
    "### **Cross-Entropy: Definition and Meaning**\n",
    "\n",
    "Cross-entropy is a cost function used to measure the difference between a model's **predicted probability distribution** and the **true probability distribution**. A lower value indicates that the model's predictions are closer to the actual labels.\n",
    "\n",
    "$$\n",
    "C(P, Q) = -\\sum_{x} P(x) \\log Q(x)\n",
    "$$\n",
    "- $P(x)$: true probability of class $x$\n",
    "- $Q(x)$: predicted probability of class $x$\n",
    "\n",
    "* **Binary Classification**\n",
    "\n",
    "    $$L(y, \\hat{y}) = -[y \\log(\\hat{y}) + (1-y) \\log(1-\\hat{y})]$$\n",
    "\n",
    "    * $y$: True label (0 or 1)\n",
    "    * $\\hat{y}$: Predicted probability of the positive class\n",
    "\n",
    "* **Multi-class Classification**\n",
    "\n",
    "    $$L(y, \\hat{y}) = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)$$\n",
    "\n",
    "    * $C$: Total number of classes\n",
    "    * $y_i$: 1 if the $i$-th class is the true label, 0 otherwise (one-hot encoded)\n",
    "    * $\\hat{y}_i$: Predicted probability for the $i$-th class\n",
    "\n",
    "### **Why Cross-Entropy is Used in Classification instead of MSE?**\n",
    "\n",
    "#### **Connection to Maximum Likelihood Estimation**\n",
    "Cross-entropy is deeply connected to the principle of **Maximum Likelihood Estimation (MLE)**. By minimizing cross-entropy, a model is optimized to make its predicted probability distribution as close as possible to the true label distribution.\n",
    "\n",
    "#### **The Vanishing Gradient Problem with MSE**\n",
    "The key issue with using **MSE** for classification lies in the **vanishing gradient problem**. In classification models, the output layer often uses activation functions like Sigmoid or Softmax, which have very small gradients when the output is close to 0 or 1. With MSE, a large error can still produce a tiny gradient, making the learning process extremely slow or ineffective.\n",
    "\n",
    "#### **Cross-Entropy's Solution**\n",
    "Cross-entropy avoids this issue through its mathematical formulation that cancels out the derivative of the activation function, ensuring that the gradient remains large even for confident but incorrect predictions. This allows for faster and more stable learning, as the model can aggressively update its weights to correct significant errors.\n",
    "\n",
    "---"
   ],
   "id": "54052cdb000aa651"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ====== Cost Function Define ====== #\n",
    "cls_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Pytorch CrossEntropyLoss Documentation\n",
    "# URL: https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "\n",
    "# # Test Cost Function\n",
    "# test_pred_y = torch.Tensor([[2, 0.1], [0, 1]])\n",
    "# test_true_y1 = torch.Tensor([1,0]).long()   # true value: class index (should be integer type)\n",
    "# test_true_y2 = torch.Tensor([0,1]).long()\n",
    "#\n",
    "# print(cls_loss(test_pred_y, test_true_y1))\n",
    "# print(cls_loss(test_pred_y, test_true_y2))"
   ],
   "id": "8a699fd30b20bb44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ===== Construct Model ====== #\n",
    "model = LinearModel()\n",
    "# model = MLPModel()\n",
    "\n",
    "print(f\"{sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters\")\n",
    "\n",
    "# ====== Construct Optimizer ====== #\n",
    "lr = 0.005\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "list_epoch = []\n",
    "\n",
    "list_train_loss = []\n",
    "list_val_loss = []\n",
    "\n",
    "list_accuracy = []\n",
    "list_accuracy_epoch = []\n",
    "\n",
    "epoch = 4000\n",
    "for i in range(epoch):\n",
    "\n",
    "    # ====== Training ====== #\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input_x = torch.Tensor(train_X)\n",
    "    true_y = torch.Tensor(train_y).long()\n",
    "    pred_y = model(input_x)\n",
    "\n",
    "    loss = cls_loss(pred_y.squeeze(), true_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    list_epoch.append(i)\n",
    "    list_train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    # ====== Validation ====== #\n",
    "    model.eval()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input_x = torch.Tensor(val_X)\n",
    "    true_y = torch.Tensor(val_y).long()\n",
    "    pred_y = model(input_x)\n",
    "\n",
    "    loss = cls_loss(pred_y.squeeze(), true_y)\n",
    "    list_val_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    # ====== Evaluation ====== #\n",
    "    if i % 200 == 0:\n",
    "\n",
    "        # ====== Calculate Accuracy ====== #\n",
    "        model.eval()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_x = torch.Tensor(test_X)\n",
    "        true_y = torch.Tensor(test_y).long()\n",
    "        pred_y = model(input_x).detach().max(dim=1)[1]\n",
    "\n",
    "        accuracy = accuracy_score(true_y, pred_y)\n",
    "        list_accuracy.append(accuracy)\n",
    "        list_accuracy_epoch.append(i)\n",
    "\n",
    "        print(f\"Epoch: {i}, Accuracy: {accuracy*100:.2f} %\")\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        fig = plt.figure(figsize=(6,3))\n",
    "\n",
    "        # ====== True Y scattering ====== #\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.scatter(test_X[:,0], test_X[:,1], c=test_y, s=5)\n",
    "        ax1.set_xlabel('x1'); ax1.set_ylabel('x2')\n",
    "        ax1.set_title('True Test Dataset y')\n",
    "\n",
    "        # ====== Predicted Y scattering ====== #\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.scatter(test_X[:,0], test_X[:,1], c=pred_y, s=5)\n",
    "        ax2.set_xlabel('x1'); ax2.set_ylabel('x2')\n",
    "        ax2.set_title('Predicted Test Dataset y')\n",
    "\n",
    "        plt.show()\n"
   ],
   "id": "86ab6f83aae7c5a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "# ====== Loss Fluctuation ====== #\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(list_epoch, list_train_loss, label='Training loss')\n",
    "ax1.plot(list_epoch, list_val_loss, '--', label='Validation loss')\n",
    "ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "ax1.set_title('Epoch vs Loss')\n",
    "\n",
    "# ====== Metric Fluctuation ====== #\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(list_accuracy_epoch, list_accuracy, marker='x', label='Accuracy metric')\n",
    "ax2.set_xlabel('Epoch'); ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "ax2.set_title('Epoch vs Accuracy')\n",
    "\n",
    "plt.show()"
   ],
   "id": "717526137ab872a2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
